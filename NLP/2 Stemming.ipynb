{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdfe6d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum\n",
      "running\n",
      "happiness\n"
     ]
    }
   ],
   "source": [
    "words = [\"maximum\", \"running\", \"happiness\"]\n",
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a68fb9",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585cf90a",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing a word to its basic root form by removing suffixes like “-ing”, “-ed”, or “-s”.\n",
    "\n",
    "It uses simple rule-based methods to cut off word endings, without understanding grammar or context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce79b1",
   "metadata": {},
   "source": [
    "# 1) Porter Stemmer\n",
    "\n",
    "Porter Stemmer is the most commonly used stemming algorithm and works using rule-based suffix removal. It removes common endings like “-ing”, “-ed”, “-ness” using predefined steps.\n",
    "\n",
    "Example words:\n",
    "playing, studies, happiness, connected\n",
    "\n",
    "Using Porter:\n",
    "playing → play\n",
    "studies → studi\n",
    "happiness → happi\n",
    "connected → connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a85b1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum------>maximum\n",
      "running------>run\n",
      "happiness------>happi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "Stemming = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word+\"------>\"+Stemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291eff80",
   "metadata": {},
   "source": [
    "# 2) Snowball Stemmer\n",
    "\n",
    "Snowball Stemmer is an improved version of Porter Stemmer (also called Porter2). It is slightly more consistent and supports multiple languages.\n",
    "\n",
    "Example words:\n",
    "running, studies, happiness\n",
    "\n",
    "Using Snowball:\n",
    "running → run\n",
    "studies → studi\n",
    "happiness → happi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0af03da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum------>maximum\n",
      "running------>run\n",
      "happiness------>happi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snow_steammer = SnowballStemmer('english')\n",
    "for word in words :\n",
    "    print(word+\"------>\"+snow_steammer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5072020",
   "metadata": {},
   "source": [
    "# 3) RegexpStemmer (Regex Stemmer)\n",
    "\n",
    "Regex Stemmer removes suffixes based on a custom regular expression pattern. It is fully customizable but very basic.\n",
    "\n",
    "Example: Remove “ing” from words.\n",
    "\n",
    "playing → play\n",
    "running → run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db5c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum---->maximum\n",
      "running---->runn\n",
      "happiness---->happi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stemmer = RegexpStemmer(regexp=\"ing$|ness$|es$|ed$\")\n",
    "for word in words:    \n",
    "    print(word+\"---->\"+reg_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fe8211",
   "metadata": {},
   "source": [
    "# 4) Lancaster Stemmer\n",
    "\n",
    "Lancaster Stemmer is more aggressive than Porter. It removes suffixes more strictly and can sometimes over-stem.\n",
    "\n",
    "Example words:\n",
    "maximum, running, happiness\n",
    "\n",
    "Using Lancaster:\n",
    "maximum → maxim\n",
    "running → run\n",
    "happiness → happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58017d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum---->maxim\n",
      "running---->run\n",
      "happiness---->happy\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lan_stemmer = LancasterStemmer()\n",
    "for word in words:    \n",
    "    print(word+\"---->\"+lan_stemmer.stem(word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
